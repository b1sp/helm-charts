global:
  region:
  domain:
  clusterType: kubernikus

# Disable the prometheus-operator kube-state-metrics sub-chart. We deploy independently.
kubeStateMetrics:
  enabled: false

# Additional scrape configuration deployed via secrets.
extraScrapeConfig: ""

prometheus-operator:
  # Just `prometheus`. The operator appends `-operator`.
  nameOverride: prometheus
  fullnameOverride: prometheus

  prometheusOperator:
    createCustomResource: false
    serviceAccount:
      create: false
    admissionWebhooks:
      enabled: false
    tlsProxy:
      enabled: false

  operator:
    serviceAccountName: default
  # Disable creation of default aggregation and alerting rules.
  defaultRules:
    create: false
  # Disable the Prometheus instance. We deploy our own Prometheis.
  prometheus:
    enabled: false
  # Disable the Alertmanager instance. We deploy our own Alertmanagers.
  alertmanager:
    enabled: false
  # Disable all exporters.
  kubeApiServer:
    enabled: false
  kubelet:
    enabled: false
  kubeControllerManager:
    enabled: false
  coreDns:
    enabled: false
  kubeDns:
    enabled: false
  kubeEtcd:
    enabled: false
  kubeScheduler:
    enabled: false
  kubeStateMetrics:
    enabled: false
  nodeExporter:
    enabled: false
  grafana:
    enabled: false

kube-state-metrics:
  customLabels:
    app: kube-state-metrics

  service:
    annotations:
      prometheus.io/port: "8080"
      prometheus.io/port_1: "8081"
      prometheus.io/targets: "kubernikus"

  resources:
    requests:
      memory: 150Mi
      cpu: 100m

prometheus-server:
  name: kubernikus

  retentionTime: 21d

  additionalScrapeConfigs:
    name: prometheus-kubernikus-additional-scrape-config
    key: scrape-config.yaml

  secrets:
    - prometheus-openstack-sso-cert

  ingress:
    enabled: true
    host: prometheus.kubernikus

  persistence:
    enabled: true
    size: 300Gi

  resources:
    requests:
      cpu: 1
      memory: 4Gi

  serviceDiscoveries:
    endpoints:
      enabled: true
      # Scrape all targets regardless of their `prometheus.io/targets` annotation.
      limitToPrometheusTargets: false
    pods:
      enabled: true
      # Scrape all targets regardless of their `prometheus.io/targets` annotation.
      limitToPrometheusTargets: false
    kubeAPIServer:
      enabled: true
    cAdvisor:
      enabled: true
    kubelet:
      enabled: true
    nodeExporter:
      enabled: true
    kubeDNS:
      enabled: true

  # The tier to use for prometheus-server alerts.
  alerts:
    tier: kks

  # Send alerts to these alertmanagers.
  alertmanagers:
    - alertmanager.eu-de-1.cloud.sap

prometheus-kubernetes-rules:
  prometheusName: kubernikus
  tier: kks

prometheus-node-exporter:
  image:
    repository: prom/node-exporter

  rbac:
    pspEnabled: false

  extraArgs:
    - --collector.filesystem.ignored-mount-points=^/(sys|proc|dev|host|etc)($$|/)
    - --collector.filesystem.ignored-fs-types=^(autofs|binfmt_misc|bpf|cgroup|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|mqueue|nsfs|overlay|proc|procfs|pstore|rpc_pipefs|securityfs|selinuxfs|squashfs|sysfs|tmpfs|tracefs)$$
    - --path.rootfs=/rootfs
    - --collector.systemd.enable-task-metrics
    - --collector.systemd.enable-restarts-metrics
    - --collector.systemd.enable-start-time-metrics
    - --collector.processes

  extraHostVolumeMounts:
    - name: dbus
      hostPath: /var/run/dbus/system_bus_socket
      mountPath: /var/run/dbus/system_bus_socket
      readOnly: true
    - name: rootfs
      hostPath: /
      mountPath: /rootfs
      readOnly: true
      mountPropagation: HostToContainer

  resources:
    requests:
      memory: 100Mi
      cpu: 100m

ntp-exporter:
  alerts:
    prometheus: kubernikus
    tier: kks

eventexporter:
  rbac:
    create: true

  metrics:
    config:
      config.yaml: |-
        metrics:
        - name: volume_mount_error_total
          event_matcher:
          - key: InvolvedObject.Kind
            expr: Pod
          - key: Reason
            expr: (FailedAttachVolume|FailedMount)
          - key: Type
            expr: Warning
          - key: Source.Component
            expr: attachdetach.*
          labels:
            node: Object.Spec.NodeName
        - name: volume_mount_success_total
          event_matcher:
          - key: InvolvedObject.Kind
            expr: Pod
          - key: Message
            expr: MountVolume.SetUp succeeded for volume .pvc-.*
          - key: Reason
            expr: SuccessfulMountVolume
          labels:
            node: Source.Host
        - name: volume_multi_attach_error_total
          event_matcher:
          - key: InvolvedObject.Kind
            expr: Pod
          - key: Message
            expr: Multi-Attach error for volume.*
          - key: Reason
            expr: FailedAttachVolume
          labels:
            node: InvolvedObject.Name
        - name: volume_mount_bad_request_total
          event_matcher:
          - key: InvolvedObject.Kind
            expr: Pod
          - key: Reason
            expr: (FailedAttachVolume|FailedMount)
          - key: Type
            expr: Warning
          - key: Source.Component
            expr: attachdetach.*
          - key: Message
            expr: ".*failed to attach ([-0-9a-f]+) volume to.*compute: Invalid request due to incorrect syntax or missing required parameters."
          labels:
            volume: Message[1]

grafana:
  enabled: false
  admin:
    existingSecret: kube-monitoring-kubernikus-grafana-admin
    userKey: adminUser
    passwordKey: adminPassword
    # Defined via secrets.
    # username: admin-user
    # password: admin-password

  rbac:
    pspEnabled: false

  # Ingress disabled by default as hosts and tls are set via secrets.
  ingress:
    enabled: false
    annotations:
      vice-president: "true"
      prometheus.io/probe: "true"
      nginx.ingress.kubernetes.io/configuration-snippet: |
        rewrite ^/$ /dashboard/db/kubernikus?refresh=1m&orgId=1&kiosk=true redirect;
      nginx.ingress.kubernetes.io/auth-tls-secret: "kube-system/ingress-cacrt"
      nginx.ingress.kubernetes.io/auth-tls-verify-depth: "3"
      nginx.ingress.kubernetes.io/auth-tls-verify-client: "optional"

    # Defined via secrets.
    # hosts:
    #   - grafana.domain.tld
    #
    # tls:
    #  - secretName: tls-grafana-domain-tld
    #    hosts:
    #      - grafana.domain.tld

  plugins: grafana-piechart-panel,natel-discrete-panel,grafana-worldmap-panel

  # Sidecar for discovering & reloading dashboard, datasource configmaps.
  sidecar:
    dashboards:
      enabled: true
      # Label that configmaps with dashboards should have to be added.
      label: kubernikus-grafana-dashboard
      # Only search for dashboards in the specified namespace.
      searchNamespace: kubernikus-monitoring

    datasources:
      enabled: true
      # Label that configmaps with datasources should have to be added.
      label: kubernikus-grafana-datasource
      # Only search for dashboards in the specified namespace.
      searchNamespace: kubernikus-monitoring

  grafana.ini:
    paths:
      data: /var/lib/grafana/data
      logs: /var/log/grafana
      plugins: /var/lib/grafana/plugins
      provisioning: /var/lib/grafana/provisioning

    server:
      protocol: http
      http_addr:
      http_port: 3000
      domain: localhost
      enforce_domain: false
      root_url: "%(protocol)s://%(domain)s:%(http_port)s"
      router_logging: false
      static_root_path: public
      enable_gzip: false
      cert_file:
      cert_key:
      socket: /tmp/grafana.sock

    users:
      allow_sign_up: false
      allow_org_create: false
      auto_assign_org: true
      auto_assign_org_role: Admin
      default_theme: dark

    auth.anonymous:
      enabled: true
      org_name: Main Org.
      org_role: Admin

    auth.proxy:
      enabled: true
      header_name: X-REMOTE-USER
      header_property: username
      auto_sign_up: true

    auth.basic:
      enabled: false

    smtp:
      enabled: false

    log:
      mode: console
      level: debug

    alerting:
      enabled: false
